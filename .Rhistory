fp <- file.path('input/NOAA_pullR',fn)
# If the NOAA station is not already downloaded, download it. This is so i dont have to manipulate input files for speed
if(!file.exists(fp)){
# If there is an error the script will continue to run
tryCatch({
# Pull the station temperature data
df <- meteo_pull_monitors(monitors = i,
var = c("TAVG", "TMIN", "TMAX"))
rec <- colnames(df[3:length(df)])
for (n in rec){
df_temp <- df[n]/10
df[n] <- df_temp
}
write.csv(df, file = fp)
},
error=function(e){cat("ERROR :",conditionMessage(e), "\n")})
}
}
#change index/rownames to be a active column - locname is consistent for next step (2)
match_data$locname <- row.names(match_data)
#change original input siteno/id to locname for match (needed to be id for last package to work)
colnames(GAGE_Dam)[colnames(GAGE_Dam)=="id"] <- "locname"
#Change Column names to match input for step 2, as well as provide appropriate colnames for join with SW location data
colnames(match_data)[names(match_data) == "id"] <- "NOAA_ID"
colnames(match_data)[names(match_data) == "name"] <- "NOAA_NAME"
colnames(match_data)[names(match_data) == "latitude"] <- "NEAR_Y"
colnames(match_data)[names(match_data) == "longitude"] <- "NEAR_X"
colnames(match_data)[names(match_data) == "distance"] <- "NEAR_DIST"
#remove geometry columns if converted from UTM
GAGE_Dam <- select(GAGE_Dam,locname, latitude, longitude)
# Merge the SW and Air Station data together (in the same format as the ArcGIS python script)
station_loc <- left_join(GAGE_Dam,match_data)
#Export this merge data set for next step (step 2 in python for annual signal)
write.csv(station_loc, file = f_out)
library(rnoaa)
nearby_stations <- meteo_nearby_stations(lat_lon_df = GAGE_Dam,
lat_colname = "LAT_GAGE", # "dec_lat_va",#
lon_colname = "LNG_GAGE", #" #"dec_long_va",
station_data = G_st,
#year_min = 2011,#This way we wont get air temp records with just 2010, but include 2010 in data pull- see below
#year_max = 2018,
var = c("TMAX", "TMIN", "TAVG"),
radius = 25,
limit = 1)
# Merge the nearby station data to one dataframe
match_data = do.call(rbind, nearby_stations) # make output of meteo nearby stations to a usable df
# Make a list of the unique NOAA station ids (remove duplicates)
noaa_pull <- unique(match_data$id)
# remove NA values (if some stations do not have lat long this will occur)
noaa_pull <- noaa_pull[!is.na(noaa_pull)]
#put in question to pull air data
# Pull the data for each of the NOAA stations identified as closest stations to the input SW stations
for (i in noaa_pull) {
fn <- sprintf('%s.csv', i)
fp <- file.path('input/NOAA_pullR',fn)
# If the NOAA station is not already downloaded, download it. This is so i dont have to manipulate input files for speed
if(!file.exists(fp)){
# If there is an error the script will continue to run
tryCatch({
# Pull the station temperature data
df <- meteo_pull_monitors(monitors = i,
var = c("TAVG", "TMIN", "TMAX"))
rec <- colnames(df[3:length(df)])
for (n in rec){
df_temp <- df[n]/10
df[n] <- df_temp
}
write.csv(df, file = fp)
},
error=function(e){cat("ERROR :",conditionMessage(e), "\n")})
}
}
#change index/rownames to be a active column - locname is consistent for next step (2)
match_data$locname <- row.names(match_data)
#change original input siteno/id to locname for match (needed to be id for last package to work)
colnames(GAGE_Dam)[colnames(GAGE_Dam)=="id"] <- "locname"
#Change Column names to match input for step 2, as well as provide appropriate colnames for join with SW location data
colnames(match_data)[names(match_data) == "id"] <- "NOAA_ID"
colnames(match_data)[names(match_data) == "name"] <- "NOAA_NAME"
colnames(match_data)[names(match_data) == "latitude"] <- "NEAR_Y"
colnames(match_data)[names(match_data) == "longitude"] <- "NEAR_X"
colnames(match_data)[names(match_data) == "distance"] <- "NEAR_DIST"
#remove geometry columns if converted from UTM
GAGE_Dam <- select(GAGE_Dam,locname, latitude, longitude)
# Merge the SW and Air Station data together (in the same format as the ArcGIS python script)
station_loc <- left_join(GAGE_Dam,match_data)
#Export this merge data set for next step (step 2 in python for annual signal)
write.csv(station_loc, file = f_out)
nearby_stations <- meteo_nearby_stations(lat_lon_df = GAGE_Dam,
lat_colname = "LAT_GAGE", # "dec_lat_va",#
lon_colname = "LNG_GAGE", #" #"dec_long_va",
station_data = G_st,
#year_min = 2011,#This way we wont get air temp records with just 2010, but include 2010 in data pull- see below
#year_max = 2018,
var = c("TMAX", "TMIN", "TAVG"),
radius = 25,
limit = 1)
GAGE_Dam$id <- GAGE_Dam$locname
nearby_stations <- meteo_nearby_stations(lat_lon_df = GAGE_Dam,
lat_colname = "LAT_GAGE", # "dec_lat_va",#
lon_colname = "LNG_GAGE", #" #"dec_long_va",
station_data = G_st,
#year_min = 2011,#This way we wont get air temp records with just 2010, but include 2010 in data pull- see below
#year_max = 2018,
var = c("TMAX", "TMIN", "TAVG"),
radius = 25,
limit = 1)
match_data = do.call(rbind, nearby_stations) # make output of meteo nearby stations to a usable df
# Make a list of the unique NOAA station ids (remove duplicates)
noaa_pull <- unique(match_data$id)
# remove NA values (if some stations do not have lat long this will occur)
noaa_pull <- noaa_pull[!is.na(noaa_pull)]
for (i in noaa_pull) {
fn <- sprintf('%s.csv', i)
fp <- file.path('input/NOAA_pullR',fn)
# If the NOAA station is not already downloaded, download it. This is so i dont have to manipulate input files for speed
if(!file.exists(fp)){
# If there is an error the script will continue to run
tryCatch({
# Pull the station temperature data
df <- meteo_pull_monitors(monitors = i,
var = c("TAVG", "TMIN", "TMAX"))
rec <- colnames(df[3:length(df)])
for (n in rec){
df_temp <- df[n]/10
df[n] <- df_temp
}
write.csv(df, file = fp)
},
error=function(e){cat("ERROR :",conditionMessage(e), "\n")})
}
}
#change index/rownames to be a active column - locname is consistent for next step (2)
match_data$locname <- row.names(match_data)
#change original input siteno/id to locname for match (needed to be id for last package to work)
colnames(GAGE_Dam)[colnames(GAGE_Dam)=="id"] <- "locname"
#Change Column names to match input for step 2, as well as provide appropriate colnames for join with SW location data
colnames(match_data)[names(match_data) == "id"] <- "NOAA_ID"
colnames(match_data)[names(match_data) == "name"] <- "NOAA_NAME"
colnames(match_data)[names(match_data) == "latitude"] <- "NEAR_Y"
colnames(match_data)[names(match_data) == "longitude"] <- "NEAR_X"
colnames(match_data)[names(match_data) == "distance"] <- "NEAR_DIST"
#remove geometry columns if converted from UTM
GAGE_Dam <- select(GAGE_Dam,locname, latitude, longitude)
# Merge the SW and Air Station data together (in the same format as the ArcGIS python script)
station_loc <- left_join(GAGE_Dam,match_data)
#Export this merge data set for next step (step 2 in python for annual signal)
write.csv(station_loc, file = f_out)
station_loc <- left_join(GAGE_Dam,match_data, by = "locname")
View(GAGE_Dam)
GAGE_Dam <- GAGE_Dam[, !duplicated(colnames(GAGE_Dam))]#remove duplicate column names locname
station_loc <- left_join(GAGE_Dam,match_data, by = "locname")
write.csv(station_loc, file = f_out)
f_out <- "input"
write.csv(station_loc, file = f_out)
f_out <- "input/GAGE_NWIS_NOAA_LocData.csv"
write.csv(station_loc, file = f_out)
library(dataRetrieval) #Retreive NWIS datasetset
library(dplyr)#for filter
library(rnoaa)# Retreive NOAA data
# --- Input Parameters
file_list <- c("conterm_bas_classif_.txt","conterm_hydro.txt","conterm_hydromod_dams.txt")#list of 'extra' GAGEII datasets of interest
dam_dis_max <- 10 #max dam distance km
SW_out_dam <- "input/SW_T_Dam"
SW_out_ref <- "input/SW_T_Ref"
f_out <- "input/GAGE_NWIS_NOAA_LocData.csv"
##---- Read location files
#initate dataframe with location information
GAGE_loc <- read.csv(list.files(pattern = "conterm_basinid.txt", recursive = TRUE, full.names = TRUE),
header=T,
stringsAsFactors=F,
colClasses=c("STAID"="character"))
for (f in file_list){
df <- read.csv(list.files(pattern = f, recursive = TRUE, full.names = TRUE),
header=T,
stringsAsFactors=F,
colClasses=c("STAID"="character"))
GAGE_loc <- merge(GAGE_loc, df, on = 'STAID')
}
rm(df)
# Column name "id" necessary to run NOAA part
GAGE_loc$id <- GAGE_loc$STAID
### --- Perform Relevant Dam Download
GAGE_loc$NWIS_Tavail <- NaN #Set column for SW Temperature records that are available for download
#make two relevant folders Dam within raw distance and ref locations
GAGE_Dam <- filter(GAGE_loc, (GAGE_loc$RAW_DIS_NEAREST_DAM < dam_dis_max & GAGE_loc$RAW_DIS_NEAREST_DAM >=0))
GAGE_Ref <- filter(GAGE_loc, GAGE_loc$CLASS == "Ref")
for (n in 1:nrow(GAGE_Ref)){
ID <- GAGE_Ref$id[n]
#ID <- "01463500" trial run
temp_df<- renameNWISColumns(readNWISdv(ID, "00010"))#, #Temperature (C)
df <- temp_df
if (nrow(df)>(0.75*365)){# at least has 75% of one year worth of temp data
GAGE_Ref$NWIS_Tavail[n] <-  1
#--- also download discharge data if available
try({
discharge_df<- renameNWISColumns(readNWISdv(ID, "00060"))#, #Daily Discharge cubic feet per second
#startDate = date_se[1],
#endDate = date_se[2]))
df <- merge(temp_df, discharge_df, on = "Date", how = 'left')
}
)
fn <- sprintf('%s.csv', ID)
fp <- file.path(SW_out_dam,fn)
write.csv(df, file = fp)
} else { #not enough data or no data available
GAGE_Ref$NWIS_Tavail[n] <-  0
}
}
fn <- sprintf('GAGE_NOAA_NWIS_Ref.csv', ID)
fp <- file.path(SW_out_ref,fn)
write.csv(df, file = fp)
write.csv(station_loc, file = f_out)
library(dplyr)#for filter
source('C:/Users/hared/Dropbox/UConn/Projects/400_TempRegimeDams/420_Data/HotDam/scripts/GAGE_NWIS_DataRetrival_ref.R', echo=TRUE)
##-- Read in full join table
df <- read.csv(list.files(pattern = "jointtbl_NWIS_NOAA_NID", recursive = TRUE, full.names = TRUE),
header=T,
stringsAsFactors=F,
colClasses=c("locname"="character"))
df <- read.csv(list.files(pattern = "jointtbl_NWIS_NOAA_NID.csv", recursive = TRUE, full.names = TRUE),
header=T,
stringsAsFactors=F,
colClasses=c("locname"="character"))
df <- read.csv(list.files(pattern = "jointtbl_NWIS_NOAA_NID.csv", recursive = TRUE, full.names = TRUE),
header=T,
stringsAsFactors=F,
colClasses=c("locname"="character"))
df <- read.csv(list.files(pattern = "jointbl_NWIS_NOAA_NID.csv", recursive = TRUE, full.names = TRUE),
header=T,
stringsAsFactors=F,
colClasses=c("locname"="character"))
View(df)
df$PURPOSES
?grepl
df$PURPOSES_NAME <- "None"
for (n in nrows(df)){
if (grepl("H",df$PURPOSES[n])){
df$PURPOSES_NAME[n] <- "HydroElectric"
}
}
for (n in nrow(df)){
if (grepl("H",df$PURPOSES[n])){
df$PURPOSES_NAME[n] <- "HydroElectric"
}
}
test <- filter(df, df$PURPOSES_NAME == "HydroElectric")
df$PURPOSES[n]
for (n in 1:nrow(df)){
if (grepl("H",df$PURPOSES[n])){
df$PURPOSES_NAME[n] <- "HydroElectric"
}
test <- filter(df, df$PURPOSES_NAME == "HydroElectric")
df$PURPOSES[n]
}
for (n in 1:nrow(df)){
if (grepl("H",df$PURPOSES[n])){
df$PURPOSES_NAME[n] <- "HydroElectric"
}
elseif (grepl("C",df$PURPOSES[n])){
df$PURPOSES_NAME[n] <- "Flood Control and Storm Water Management"
}
}
for (n in 1:nrow(df)){
if (grepl("H",df$PURPOSES[n])){
df$PURPOSES_NAME[n] <- "HydroElectric"
}
ifelse (grepl("C",df$PURPOSES[n])){
df$PURPOSES_NAME[n] <- "Flood Control and Storm Water Management"
}
}
for (n in 1:nrow(df)){
if (grepl("H",df$PURPOSES[n])){
df$PURPOSES_NAME[n] <- "HydroElectric"
}
else (grepl("C",df$PURPOSES[n])){
df$PURPOSES_NAME[n] <- "Flood Control and Storm Water Management"
}
}
for (n in 1:nrow(df)){
if (grepl("H",df$PURPOSES[n])){
df$PURPOSES_NAME[n] <- "HydroElectric"
}
if (grepl("C",df$PURPOSES[n])){
df$PURPOSES_NAME[n] <- "Flood Control and Storm Water Management"
}
}
test <- filter(df, df$PURPOSES_NAME == "Flood Control and Storm Water Management")
list("I","H","C","N","S","R","P","F","D","T","G","O")
list("Irrigation", "Hydroelectric","Flood Control","Navigation","Water Supply","Recreation","Fire Protection","Fish and Wildlife Pond","Debris Control","Tailings","Grade Stabilzation","other")
abbv <- list("I","H","C","N","S","R","P","F","D","T","G","O")
name <- list("Irrigation", "Hydroelectric","Flood Control","Navigation","Water Supply","Recreation","Fire Protection","Fish and Wildlife Pond","Debris Control","Tailings","Grade Stabilzation","other")
purpose <- do.call(rbind, Map(data.frame, A=abbv, B=name))
View(purpose)
purpose <- do.call(rbind, Map(data.frame, Purp_abbv=abbv, Purp_name=name))
i in 1:nrow(purpose)
?which
for (i in purpose$Purp_abbv){
j <- which(Purpose$abbv == i, arr.ind=TRUE)
for (n in 1:nrow(df)){
if (grepl(i,df$PURPOSES[n])){
df$PURPOSES_NAME[n] <- j
}
}
}
abbv <- list("I","H","C","N","S","R","P","F","D","T","G","O")
name <- list("Irrigation", "Hydroelectric","Flood Control","Navigation","Water Supply","Recreation","Fire Protection","Fish and Wildlife Pond","Debris Control","Tailings","Grade Stabilzation","other")
purpose <- do.call(rbind, Map(data.frame, Purp_abbv=abbv, Purp_name=name))
for (i in purpose$Purp_abbv){
j <- which(Purpose$abbv == i, arr.ind=TRUE)
for (n in 1:nrow(df)){
if (grepl(i,df$PURPOSES[n])){
df$PURPOSES_NAME[n] <- j
}
}
}
abbv <- list("I","H","C","N","S","R","P","F","D","T","G","O")
name <- list("Irrigation", "Hydroelectric","Flood Control","Navigation","Water Supply","Recreation","Fire Protection","Fish and Wildlife Pond","Debris Control","Tailings","Grade Stabilzation","other")
purpose <- do.call(rbind, Map(data.frame, Purp_abbv=abbv, Purp_name=name))
for (i in purpose$Purp_abbv){
j <- which(purpose$abbv == i, arr.ind=TRUE)
for (n in 1:nrow(df)){
if (grepl(i,df$PURPOSES[n])){
df$PURPOSES_NAME[n] <- j
}
}
}
j,k] <- which(purpose$Purp_abbv == i, arr.ind=TRUE)
[j,k] <- which(purpose$Purp_abbv == i, arr.ind=TRUE)
which(purpose$Purp_abbv == i, arr.ind=TRUE)
j <- which(purpose$Purp_abbv == i, arr.ind=TRUE)
df$PURPOSES_NAME[n] <- purpose$Purp_name[j]
?filter
?filter
csv <- filter(df,df$PURPOSES_NAME[j])
csv <- filter(df,df$PURPOSES_NAME==df$PURPOSES_NAME[j])
df$PURPOSES_NAME[j]
fn <- sprintf('GAGE_NOAA_NWIS_Ref.csv', ID)
?sprintf
fn <- paste0(purpose$Purp_name[j],'.csv')
fp <-  file.path('input',fn)
df$PURPOSES_NAME <- "None"
abbv <- list("I","H","C","N","S","R","P","F","D","T","G","O")
name <- list("Irrigation", "Hydroelectric","Flood Control","Navigation","Water Supply","Recreation","Fire Protection","Fish and Wildlife Pond","Debris Control","Tailings","Grade Stabilzation","other")
purpose <- do.call(rbind, Map(data.frame, Purp_abbv=abbv, Purp_name=name))
for (i in purpose$Purp_abbv){
j <- which(purpose$Purp_abbv == i, arr.ind=TRUE)
for (n in 1:nrow(df)){
if (grepl(i,df$PURPOSES[n])){
df$PURPOSES_NAME[n] <- purpose$Purp_name[j]
}
}
csv <- df %>% filter(df$PURPOSES_NAME==df$PURPOSES_NAME[j])
fn <- paste0(purpose$Purp_name[j],'.csv')
fp <-  file.path('input',fn)
write.csv(csv, file = fp )
}
df$PURPOSES_NAME[j]
View(df)
purpose$Purp_name[j]
df$PURPOSES[n]
purpose$Purp_name[j]
j <- which(purpose$Purp_abbv == i, arr.ind=TRUE)
purpose$Purp_name[12]
purpose$Purp_name[8]
for (i in purpose$Purp_abbv){
j <- which(purpose$Purp_abbv == i, arr.ind=TRUE)
for (n in 1:nrow(df)){
if (grepl(i,df$PURPOSES[n])){
df$PURPOSES_NAME[n] <- purpose$Purp_name[j]
}
}
csv <- df %>% filter(df$PURPOSES_NAME==df$PURPOSES_NAME[j])
fn <- paste0(purpose$Purp_name[j],'.csv')
fp <-  file.path('input',fn)
write.csv(csv, file = fp )
}
purpose$Purp_name[6]
j <- 6
fn <- paste0(purpose$Purp_name[j],'.csv')
j <- 1
for (n in 1:nrow(df)){
if (grepl(i,df$PURPOSES[n])){
df$PURPOSES_NAME[n] <- purpose$Purp_name[j]
}
}
csv <- df %>% filter(df$PURPOSES_NAME==df$PURPOSES_NAME[j])
fn <- paste0(purpose$Purp_name[j],'.csv')
fp <-  file.path('input',fn)
write.csv(csv, file = fp )
df$PURPOSES_NAME[j]
purpose$Purp_name[j]
purpose$Purp_name[j]
purpose$Purp_name[1]
for (i in purpose$Purp_abbv){
j <- which(purpose$Purp_abbv == i, arr.ind=TRUE)
for (n in 1:nrow(df)){
if (grepl(i,df$PURPOSES[n])){
df$PURPOSES_NAME[n] <- purpose$Purp_name[j]
}
}
csv <- df %>% filter(df$PURPOSES_NAME==purpose$Purp_name[j])
fn <- paste0(purpose$Purp_name[j],'.csv')
fp <-  file.path('input',fn)
write.csv(csv, file = fp )
}
for (i in purpose$Purp_abbv){
j <- which(purpose$Purp_abbv == i, arr.ind=TRUE)
for (n in 1:nrow(df)){
if (grepl(i,df$PURPOSES[n])){
df$PURPOSES_NAME[n] <- purpose$Purp_name[j]
}
}
csv <- df %>% filter(df$PURPOSES_NAME==j)
fn <- paste0(purpose$Purp_name[j],'.csv')
fp <-  file.path('input',fn)
write.csv(csv, file = fp )
}
for (i in purpose$Purp_abbv){
j <- which(purpose$Purp_abbv == i, arr.ind=TRUE)
for (n in 1:nrow(df)){
if (grepl(i,df$PURPOSES[n])){
df$PURPOSES_NAME[n] <- purpose$Purp_name[j]
}
}
csv <- df %>% filter(df$PURPOSES_NAME==j)
fn <- paste0(purpose$Purp_name[j],'.csv')
fp <-  file.path('input',fn)
write.csv(csv, file = fp )
}
df <- read.csv(list.files(pattern = "jointbl_NWIS_NOAA_NID.csv", recursive = TRUE, full.names = TRUE),
header=T,
stringsAsFactors=F,
colClasses=c("locname"="character"))
df$PURPOSES_NAME <- "None"
abbv <- list("I","H","C","N","S","R","P","F","D","T","G","O")
name <- list("Irrigation", "Hydroelectric","Flood Control","Navigation","Water Supply","Recreation","Fire Protection","Fish and Wildlife Pond","Debris Control","Tailings","Grade Stabilzation","other")
purpose <- do.call(rbind, Map(data.frame, Purp_abbv=abbv, Purp_name=name))
for (i in purpose$Purp_abbv){
j <- which(purpose$Purp_abbv == i, arr.ind=TRUE)
for (n in 1:nrow(df)){
if (grepl(i,df$PURPOSES[n])){
df$PURPOSES_NAME[n] <- purpose$Purp_name[j]
}
}
csv <- df %>% filter(df$PURPOSES_NAME==j)
fn <- paste0(purpose$Purp_name[j],'.csv')
fp <-  file.path('input',fn)
write.csv(csv, file = fp )
}
View(csv)
View(df)
load("E:/NRE_5335/HotDamTest/HotDam/.RData")
library
library(tidyverse) # for extract geomtry to two columns
library(dataRetrieval)
install.packages(dataRetrieval)
library(dplyr)
library(tidyverse) # for extract geomtry to two columns
## Function Inputs
install.packages(rnoaa)
install.packages(dataRetrieval)
library(rnoaa)# noaa station search and download
library('rnoaa')# noaa station search and download
## Function Inputs
install.packages('rnoaa')
install.packages('dataRetrieval')
library(rnoaa)# noaa station search and download
library(dplyr)
library(tidyverse) # for extract geomtry to two columns
library(dataRetrieval)
#Set input parameters
DamDistanceMax <- 10 # Max km away a station is from a dam (raw straight-line)
f_out <- "DataOutput/NWISDamsLoc_NOAA_Match_.txt"
f_in <- "DataInput/GAGEII_NWIS_TempwDams.csv"
delim <- "," #  "\t",#
air_out <- "DataOutput/NOAA_pullR"
SW_out <- "DataInput/SWTemp_10km"
#Get a list of all the NOAA stations currently available
#G_st <- ghcnd_stations() #Use first time, or if need of an update - takes a long time.
load("DataInput/NOAA_Stations_All.RData")#Already loaded all NOAA station data as G_st
# Read full SW location dataset
# Location data has to use column names Latitude and Longitude, or Northing and Easting if UTM
lat_lon_SW_df <- read.csv(f_in,
sep = delim,
header=T,
stringsAsFactors=F,
colClasses=c("Sheet1_gag"="character"))# Makes sure ids that start with '0' are mantained
#change current, used column names to readable - hard code, need to change
colnames(lat_lon_SW_df)[colnames(lat_lon_SW_df)=="Sheet1_gag"] <- "id"
colnames(lat_lon_SW_df)[colnames(lat_lon_SW_df)=="Sheet1_g_4"] <- "latitude"
lat_lon_SW_df$dataavailable <- NaN #Set column for SW Temperature records that are available for download
for (n in 1:nrow(lat_lon_SW_df)){
ID <- lat_lon_SW_df$id[n]
if ((nchar(as.character(ID)) >= 8) & lat_lon_SW_df$Dis_Crow_km[n] < DamDistanceMax ){ #only use usgs names (speeds up process!)
try(
station_df<- renameNWISColumns(readNWISdv(ID, "00010"))#, #Temperature (C)
#startDate = date_se[1],
#endDate = date_se[2]))
)
# Create a new column in the SW location data table to indicate if there is data available for the time frame
# requested, if the whole list of SW is not run the remaining will be '0's as well.
if (nrow(station_df)> 0){
lat_lon_SW_df$dataavailable[n] <-  1
fn <- sprintf('%s.csv', ID)
fp <- file.path(SW_out,fn)
write.csv(station_df, file = fp)
} else { #will this catch < 8 ID length
lat_lon_SW_df$dataavailable[n] <-  0
}
}
}
